# NN_transplant
## _A precious lesson to learn for a neural network freshman (<- yeah ...... it's me~).

## Description:
#### This 3-layer neural network was referred from CS231n course of Stanford university. And the backbone of these codes was referred from mattmazur/simple_neural_network. I intended to realized the word2vec network based on the structure of mattmazur's code. Let's see how far I could go!

#### While...since the model was designed receiving only one input a time, it performed like a linear Softmax classifier even though the structure as well as the gradient descending algorithm were designed for realizing a 3-layer neural network (Sigmoid function applied for hidden layer, and Softmax function applied for output layer).

## Structure:  
### Input layer: 2 neurons representing X and Y axis
### Hidden layer: 100 neurons
### Output layer: 3 neurons representing 3 classess

